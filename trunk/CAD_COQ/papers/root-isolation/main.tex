\documentclass{mscs}
\usepackage[pdftex]{graphicx}
\usepackage{amsmath, amsfonts}
\usepackage{listings}
\usepackage{xcolor}
\input{macro}

\begin{document}
\title{A formal study of Bernstein coefficients and polynomials}
\author{Yves Bertot, Assia Mahboubi, Fr\'ed\'erique Guilhot}

\maketitle

\section{introduction}
Bernstein coefficients provide a discrete approximation of polynomials
inside a bounded interval. As such they are useful tools to solve
problems like locating the roots of polynomials, isolating these roots
or solving systems of inequations with polynomial members.  In
computer aided design, they are also used intensively as they give an
efficient tool to draw curves that are controlled by points that users
can grab and drag, with instantaneous and intuitive feedback on the
shape the curve will take as the control points move around.
Bernstein coefficients are closely related to splines and Bezier curves.

Bernstein coefficient are defined for a given polynomial, a given
degree, and a given interval. if the degree is \(n\), then
the coefficients form a sequence of size \(n+1\). In
this paper, we are interested in three important properties of these
coefficients:

\begin{enumerate}
\item if the coefficients taken in order exhibit exactly one sign change,
  then the polynomial is guaranteed to have exactly one root inside
  the interval.
\item  if all coefficients have the same sign, then the
  polynomial is guaranteed to have no root inside the interval
  for which they have been computed.
\item there is an easy method to compute Bernstein coefficients for
  the two intervals obtained when splitting a larger interval from the
  Bernstein coefficients for this larger interval.
\end{enumerate}

In this paper, we describe a formal proof of these three properties,
concentrating on the second and third properties. These proofs will be
done in the setting of polynomials with the rational coefficients and
rational values.

in the following, we will assume that we are working with polynomials
whose roots are all simple. Starting from an arbitrary polynomial it
is easy to produce another polynomial with the same roots but all of
them simple, simply by dividing it by the greatest common divisor of
this polynomial and its derivative.

The main plan of the proof of the first property is to describe a
sequence of pairs \((I_0, P_0)\) to \((I_3, P_3)\), each pair
containing an interval and a polynomial, so that every root of
polynomial \(P_i\) inside \(I_i\) is in bijective correspondance with
a root of polynomial \(P_{i+1}\) in the interval \(I_{i+1}\).  The
first interval and the first polynomial are simply \(I\) and \(P\).
The last interval is \((0, +\infty)\) and the last polynomial is \(b_0
+ b_1 X + \cdots + b_n X^n\), where the coefficients \(b_i\) have the
same sign as the Bernstein coefficients.  Going from \(P_i\) to
\(P_{i+1}\) we apply a given transformation.  The first transformation
is a change of variable so that \(I_1\) is \((0,1)\) and \(P_1(x) =
P_0(x \times r + (1 - x) l)\).  The second transformation is so that
\(I_2\) is \((1,+\infty)\) and \(P_2(x) = 0\) exactly when \(P_1(1/x)
= 0\), as long as \(x\neq 0\).  The third transformation is a
translation so that \(I_3 = (0,+\infty)\) and \(P_3(x) = P_2(1+x)\).
We will show that the condition on Bernstein coefficients simply
boils down to Descartes' law of sign for polynomial \(P_3\) in the
case where there exactly one sign change this polynomial's coefficients.
This path from one polynomial to another is described in section~\ref{sec:Bernstein}

Descartes' law of signs provides a sufficient criterion for the
existence of exactly one root between 0 and \(+\infty\).  In its
most general form, this law
expresses a relation between the number of roots of a polynomial
between 0 and \(+\infty\) and the number of sign changes in the
coefficients of this polynomial.  The number of sign changes is larger
than the number of roots and the difference between the two numbers is
a multiple of 2.  Thus, if the number of sign changes is 1, there is
exactly one root between 0 and \(+\infty\).

For our development, we only prove the corollary  of
Descartes' law of signs for the case where there is only one sign
change.  Expressing Descartes' law on the coefficients of polynomial
\(P_3\) yields directly a law expressed in terms of sign changes for
Bernstein's coefficients of \(P\) with respect to the interval
\((l,r)\).   This proof is done in section~\ref{sec:descartes}.

Another part of our work is to describe dichotomy.  Knowing Bernstein
coefficients for a polynomial and a given interval, it is easy to
compute the Bernstein coefficients for the two half intervals, using
the algorithm known as "de Casteljau".  In the process, we increase
the precision of the approximation given by the Bernstein
coefficients.  De Casteljau's algorithm is a simple combinatorial
algorithm based on taking arithmetic means of successive coefficients.
To justify this combinatorial process we need to show that Bernstein
coefficients actually are the coefficients of the polynomial in a
different basis from the usual monomials.  This is done in section~\ref{sec:dicho}.

Most of our proofs were made using only rational numbers as numeric
values.  Thus, we work with type of numbers where equality and
comparison are decidable and the process we described can effectively
be used in a decision procedure.

When considering only rational numbers, the existence of roots takes a
different meaning: if a polynomial has a single simple real root in an
interval, this root may not be rational.  However, we can use a
corresponding property on rational numbers: there exists a
sub-interval inside which the absolute value of the slope is bounded
below, and such that the values of the polynomial at the sub-interval
bounds have opposite signs.  In a similar vein, the intermediate value
theorem does not hold with rational numbers, but a corresponding
statement, expressed as a bounded-value property, does.  Our proof
development relies on this approach.  We describe the formal aspects
of this approach to describing roots in section~\ref{sec:rational}.

Our work on Bernstein coefficients is an important stepping stone
to address various aspects of real algebraic numbers, decision
procedures for real arithmetic, and more ambitious algorithms like
cylindrical decomposition.

The formal work described in this paper has been performed using 
the Coq system\cite{coqart}, with ssreflect extension
\cite{GONTHIER:2008:INRIA-00258384:4}.  We think some characteristics
of the proof system played a key role in making this development
possible.  We describe these key aspects in section~\ref{sec:formal}.

\section{The dichotomy process}\label{ssec:dicho}
Let $P \in \mathbb{Q}[X]$ be an arbitrary polynomial. To isolate its
roots, we start by producing an interval that is large enough to have
all the real roots of the polynomial inside.  We place
this large interval as the only element in a working list.  Then we
process the working list using a criterion for each interval that can
give three kinds of answers.
\begin{enumerate}
\item The first possible answer is that we know a sufficient condition
for a given interval to contain no root of the polynomial.  This interval
can be removed from the working list.
\item The second possible answer is that we know a sufficient condition
for a given interval to contain exactly one root of the polynomial. This
interval can be removed from the working list and added to the result.
\item the third possible answer is that we cannot know whether the interval
contains zero, one, or several roots.  In this case, the interval is removed
from the working list, split in two, and the two sub-intervals are added
to the working list.
\end{enumerate}

To start the dichotomy process, we need to produce a first interval
that is guaranteed to contain all the roots of a polynomial.  Here is
a solution.  Let $P = \sum_{i = 0}^dp_iX^i$ with $p_d \neq 0$. Let:
$$C(P) := \sum_{i = 0}^d\left|\displaystyle{\frac{p_i}{p_d}}\right|$$
The constant $C(P)$ is called the Cauchy bound of $P$ and has the
following property:
$$\forall x \in \mathbb{R}, P(x) = 0 \Rightarrow |x|\leq C(P)$$
\begin{proof}
Let $x\in \mathbb{R}$ a root of $P$. Since $C(P) \geq 1$, if $|x|\leq
1$, the property is  trivial. Otherwise if $|x| < 1$, then:
$$p_d x = - \sum_{i = 0}^{d - 1} p_i x^{i - p + 1}$$
Hence:
$$|p_d| |x| = \sum_{i = 0}^{d - 1} |p_i| |x|^{i - p + 1} \leq
\sum_{i = 0}^{d - 1} |p_i|$$
And finally $|x| \leq C(P)$.
\end{proof}

In section~\ref{sec:Bernstein} we show how to compute the three-way
criterion for an arbitrary interval.  It is based on a list of coefficients
known as Bernstein coefficients, which need to be computed for each
interval, and then observed using a simple rule.  In
section~\ref{ssec:split}, we show that the list of Bernstein coefficients
for sub-intervals is easy to derive from the list of Bernstein coefficients
for the previous interval.

\section{Describing roots of a polynomial in the rational setting}
\label{sec:rational}
In mathematics, we are accustomed to use several fields that have different
properties regarding the existence of roots of polynomials.  The most general
case is the the case of algebraically closed fields, like the fields of complex
numbers.  In these fields, any polynomial of degree larger than 1 and
with the coefficients in the field is guaranteed to have a root in the field.
For instance, any polynomial with complex coefficients is guaranteed to have
a root that is a complex number.

Then, we can consider an itermediary kind of fields, known as real closed
fields, like the field of real numbers.  These fields are
ordered and contain enough elements
so that they enjoy the existence of the {\em intermediate value theorem}:
any polynomial that has a negative value in one point \(a\) and a positive value
in another point \(b\) is guaranteed to have a root at some point between
\(a\) and \(b\).  The field of real numbers satisfies this property.

Then, we can consider smaller fields, like the field of rational numbers.
Here we don't have the {\em intermediate value theorem} anymore.  Still, it
makes sense to say that a bounded interval in the field of rational number
may contain exactly one root because the polynomial's curve crosses the
x-axis in exactly one point, which can be approximated arbitrarily close,
even if it does not really exist in the field of rational numbers.  This
what we want to make precise in the next two sections.


\subsection{Criteria for the existence of a unique root}
We concentrate on a sufficient criterion for the existence of a root inside
an interval.  This criterion is strong enough to build a Cauchy sequence
whose limit in the real numbers would be the root.  Our criterion is
based on slopes.

Ensuring that the slope is positive or
negative is some interval helps making sure that there are not two
roots.  In our constructive setting, we
have a stronger property that the slope is separated from 0 by a given ratio.
In the case of positive slopes, we
write the slope requirement for a polynomial \(p\) inside a given interval
\(I\) as follows:
\[\exists k, 0 < k \wedge \forall x y, x \in I \wedge y \in I
\wedge x < y \Rightarrow k(y - x) < p(y) - p (x) \]

Depending on the kind of interval that we will consider, we will have
two different ways to express the existence of a single root in the
interval.

\begin{enumerate}
\item If the interval is bounded, we express that the interval can be
  decomposed into three parts, the first part where the polynomial's
  value is always negative (\(I_1\) in Figure~\ref{bounded_decompose}, the second part where the polynomial's
  value goes from negative to positive with a requirement on the
  slope (\(I_2\) in Figure~\ref{bounded_decompose}, and the third part where the polynomial's value is always
  positive (\(I_3\) in Figure \ref{bounded_decompose}).
\begin{figure}\label{bounded_decompose}
\begin{center}
\includegraphics[clip=true,trim= 2cm 7cm 0cm 9cm,scale=0.3]{bounded_decompose.pdf}
\end{center}
\caption{A sufficient criterion for the existence of a single root in a bounded interval}
\end{figure}
\item If the interval is unbounded, we express that the interval can
  be decomposed into two parts, the first part where the polynomials
  value is always negative (\(I_1\) in
  Figure~\ref{unbounded_decompose}, and the second part where there is
  a requirement on the slope with a positive slope (\(I_2\) in
  Figure~\ref{unbounded_decompose}).
\begin{figure}\label{unbounded_decompose}
\begin{center}
\includegraphics[clip=true,trim=2cm 3cm 2cm 9cm, scale=0.3]{unbounded_decompose.pdf}
\end{center}
\caption{A sufficient criterion for the existence of a single root in an unbounded interval}
\end{figure}
\end{enumerate}
\subsection{Finding locations where a polynomial's value is arbitrarily small}
While we can't be sure to produce a rational value on which the
polynomial of interest returns the zero value, we at least need to be
able to produce an input for which the polynomial's value is
arbitrarily small. In classical mathematics once we know that the
polynomial takes values of opposite sign at the bounds of an interval,
we know that there is a root for this polynomial in this interval,
thanks to the intermediate value theorem. For this work, we establish
a simplified constructive replacement of the intermediate value
theorem especially for polynomials.  The statement we prove has the following
form:
\[\forall p~x~y~\varepsilon, 0 < \varepsilon \rightarrow
p(x) < 0 \leq p(y) \rightarrow\\
\exists x'~ y', -\varepsilon \leq p(x') < 0 \leq p(y') \leq \varepsilon \wedge
x \leq x' < y' \leq y\]

We again rely on reasoning about slopes. First, we establish that the
slope of any polynomial is bounded in absolute value on any bounded
interval. This gives us a way to establish that polynomials
enjoy a property that is akin to but stronger
than uniform continuity. Starting from an interval and
a polynomial we can produce a coefficient \(k\) so that the variation
of the polynomial between two points \(x\) and \(y\) is smaller than
\(|k\times(y-x)|\).

Given an arbitrary small and positive \(\varepsilon\), a polynomial
\(p\), and a bounded interval \((l,b)\) so that \(p(l) < 0 < p(r)\),
we want to produce an input \(x_0\) so that \(0 < p(x_0) <
\varepsilon\).  We proceed by taking an upper bound \(k\) of the slope for
this interval and this polynomial and choosing a large number \(n\) so
that \(\frac{r-l}{n} < \frac{\varepsilon}{k}\).  We then consider the
\(n+1\) values \(a_i =l + \frac{i\times (r-l)}{n}\). We then solve a
discrete problem over the values \(a_i\). We simply need to find the
smallest \(a_j\) of these inputs for which the polynomial's value is
positive. The preceding value \(a_{j-1}\) necessarily is a value where
the polynomial is nonpositive. Thanks to the bound on the slope and
because the distance between consecutive \(a_i\)'s is smaller than
\(\frac{\varepsilon}{k}\), we are guaranteed that the value in \(a_i\)
is positive and smaller than \(\varepsilon\).  Note that this approach
makes it possible to bound the polynomial's value in the interval
\((a_{j-1},a_j)\) and to guarantee the existence of a root inside this
interval, however it does not provide for the uniqueness of the root.

Our algorithm is illustrated in figure~\ref{ivt}, where the distance
between the \(a_i\)'s is chosen according to the maximal slope
occurring between \(l=a_0\) and \(r=a_{12}\). The point selected by
our algorithm is \(a_6\), even though there are more roots in the
vicinity of \(a_1\) and \(a_2\) but neither \(a_1\) nor \(a_2\) is a
point where the polynomial takes a positive value.  The point \(a_{11}\) could
also be eligible, but it is not the smallest one.
\begin{figure}
\label{ivt}
\begin{center}
\includegraphics[clip=true,trim=0cm 9cm 2cm 9cm,scale=0.5]{ivt.pdf}
\end{center}
\caption{Bounding a polynomials value}
\end{figure}

\section{A simple form of Descartes' law of signs}
\label{sec:descartes}
\subsection{A Geometrical explanation of the proof}
Let's first describe a simple graphical argument based on curves for polynomial functions between 0 and \(+\infty\), as shown in figure~\ref{graph-desc}.
\begin{figure}
\begin{center}
\includegraphics[width=0.5\textwidth]{alternated2.png}
\end{center}
{(a) non-negative coefficients, first one non-zero,\\
(b) non-negative coefficients, first one zero,\\
(c) first coefficient negative, all others non-negative,\\
(d) one sign change, first coefficient zero,\\
(e) one sign change, first coefficient negative}

\caption{\label{graph-desc}
Classes of polynomials with or without
sign change}
\end{figure}
To describe our proof, we assume that new polynomials are built from
existing ones by multiplying them by the polynomial \(X\) and adding a
constant; an operation that is known as ``Horner's scheme''.
Polynomials with one sign change and a positive principal coefficient
are obtained by starting with a positive constant, applying Horner's
scheme a certain number of times with non-negative constants, then
applying it a negative constant, and then applying it again a certain
number of times with non-positive constants.

Polynomials with only non-negative coefficients have curves which look
like the curves (\ref{graph-desc}-a) or (\ref{graph-desc}-b) depending on whether the first
coefficient is 0, adding a positive coefficient to a polynomial of the
form (\ref{graph-desc}-a) or (\ref{graph-desc}-b) yields a polynomial of the form (\ref{graph-desc}-a), multiplying a
polynomial of the form (\ref{graph-desc}-a) or (\ref{graph-desc}-b) by the polynomial \(X\) yields a new
polynomial of the form (\ref{graph-desc}-b).  Thus, Horner's scheme with non-negative
constants keeps polynomials in the (a-b) form.  Then, when applying
Horner's scheme with a negative coefficient (thus introducing a sign
change), the multiplication by \(X\) first builds a polynomial of the
(\ref{graph-desc}-b) form, and adding a negative constant, one obtains a curve whose
shape is given by (\ref{graph-desc}-c).  From then on, multiplying a polynomial of the
form (\ref{graph-desc}-c), (\ref{graph-desc}-d), or (\ref{graph-desc}-e) by \(X\) yields a a polynomial of the (\ref{graph-desc}-d) form; adding a
negative constant to a polynomial of the form (\ref{graph-desc}-d) or (\ref{graph-desc}-e) yields a
polynomial of the (\ref{graph-desc}-e) form.  Polynomials of the form (\ref{graph-desc}-d) or (\ref{graph-desc}-e)
share the following characteristic: there exists a positive value
\(x\), so that the polynomial has a negative value between 0 and
\(x\), and the slope of the curve is strictly positive above
\(x\).  Because of the slope condition, we can also find a point where
the polynomial is positive.

Let us now give a more precise proof, outlining the concepts that are
used in the formal proof.

\subsection{Lemmas for polynomials with non-negative coefficients}
Polynomials are simply encoded by their lists of coefficients, evaluating
a polynomials on a given number is done recursively following Horner's scheme,
and recognizing polynomials with only non-negative coefficients is also
done using a simple recursive function, written in the following form:
\begin{lstlisting}
  Fixpoint |*all_pos_or_zero*| (l:seq Qcb) : bool :=
  if l is a::tl then (0 <= a) && all_pos_or_zero tl else true.
\end{lstlisting}
As a reminder, the Coq syntax variant that we use, {\tt ssreflect},
privilegies boolean predicates, so that {\tt (0 <= a)} stands for a boolean
value computed by a recursive function instead of a proposition as in
standard Coq litterature.  Also, the type {\tt Qcb} stands for a representation
rational number as fractions in canonical form (hence the letter {\tt c}), where
the verification that the fraction is in canonical form is also expressed
using a boolean function (hence the letter {\tt c}).  Since these numbers
are in canonical form, the equality test between two fractions is simply based
on syntactic equality, in other words Leibnitz equality.  The type constructor
{\tt seq } is a type for lists, with extra constraints on the types can be
stored in such lists: equality must be decidable, a feature that can then be
exploited intensively by the {\tt ssreflect} package
\cite{GONTHIER:2008:INRIA-00258384:4}.

We should remark that polynomials satisfying the boolean predicate 
{\tt all\_pos\_or\_zero} may not contain any positive coefficients: for this
reason, we cannot guarantee that they are increasing or strictly positive
anywhere between 0 and \(+\infty\).

We prove easily by induction on lists that if they contain only non-negative
coefficients, then the corresponding polynomial always has a postive value
in \((0,+\infty)\) and from then, we also prove by induction that
any polynomial with only non-negative coefficients is increasing.

We then prove that for every polynomial \(P\)  with non-negative coefficients,
the product \(x \times P(x)\) can be made arbitrarily close to 0.

\subsection{Two lemmas on slopes}
A first lemma on slopes concerns the existence of points where a
polynomial \(P\) takes a value above an arbitrary bound \(a\).  If the slope
is bounded below by a positive ratio \(k\), this is guaranteed as it
suffices to take a value that is large enough.  As the proof is
constructive, we need to be more precise: assuming the slope is larger
than \(k\) for any \(y\) larger than \(x_1\), it suffices to take any
value larger than \(x_1 + \frac{a - P(x_1)}{k}\).  This result is
remembered in our development under the name {\tt above\_slope}.

A second lemma on slopes concerns the slope of a product of the form
\(x \times P(x)\).  This
lemma reproduces the known formulas for the derivative of products of derivable
functions, but is expressed solely in terms of lower bounds of slopes.
{\sl if  a function \(f\) has a slope larger than or equal to a non-negative
ratio \(k_f\) when \(x\) is larger than a certain bound \(a\), then
then the slope of the product \(x \times f(x)\) is larger than
\(a k_f + f(x)\)}.

This statement requires \(f\) to have a positive slope, but it leaves open
whether \(f(x)\) is positive or not.  In particular, the values \(a\) and
\(k_r\) can be fixed for a large interval: we intend \(a\) to be the lower
bound of interval \(I_2\) as used in the criterion for existence of a unique
root in an unbounded interval (see Figure~\ref{unbounded_decompose}).

\subsection{Polynomials with exactly one sign change}
We can then address polynomials with exactly one sign change.  We want
to show that these polynomials have exactly one root.  We exhibit the
two intervals described in the criterion for unbounded intervals (see
Figure~\ref{unbounded_decompose}) the positive value \(x_1\) and the
positive ratio \(k\) such that the polynomial is negative in the
interval \((0, x_1)\) and the slope between any two values above
\(x_1\) is larger than \(k\).

To detect polynomial with exactly one sign changes, we use two recursive
functions.  The first one, which we call {\tt alternate\_1}, recognizes
polynomials with at least one positive coefficient, preceded by any number
of non-positive coefficients (possibly 0) and followed by only non-negative
coefficients, as checked by {\tt all\_pos\_or\_zero}.  This function is
defined as follows:
\begin{lstlisting}
Fixpoint alternate_1 (l:seq Qcb) : bool :=
  if l is a::tl then
     if 0 < a then all_pos_or_zero tl else alternate_1 tl
  else false.
\end{lstlisting}
The second function, which we call {\tt alternate}, checks for the
presence of at least one negative coefficient and then calls {\tt alternate\_1}.
Thus, {\tt alternate} calls itself recursively
as long as it finds zero coefficients, the function {\tt alternate\_1}
also calls itself recursively as long as it finds
non-positive arguments.

As we have two recursive functions, {\tt alternate\_1} and {\tt alternate},
we actually need to perform two proofs by induction.  Each proof by induction
shows that some invariant is satisfied.

The invariant for {\tt alternate\_1}
must be satisfied by a polynomial \(P\) that may or may not contain a negative
coefficient, so that this invariant cannot guarantee the existence of
places where the polynomial takes a negative value.  Instead, this invariant
guarantees for any positive \(\varepsilon\) the existence of a positive {\tt x}
and a \(k\) so that:
\begin{enumerate}
\item for any \(y\) between \(0\) and \(x\), \(P(y) \leq P (x)\) ,
\item the slope between two points larger \(x\) is guaranteed to be larger
than \(k\),
\item the number \(x \times P(x)\) is between \(0\) and \(\varepsilon\).
\end{enumerate}

The invariant for {\tt alternate} is exactly the criterion we use
to describe the existence of exactly one root in an unbounded interval.
This proof by induction is done by induction on the list.  The empty list
does not satisfy the predicate {\tt alternate} so that this case is
taken care of easily.  The other case is when the polynomial is described
by a list of the form {\tt \(a\)::\(l\)}, so that \(l\) represents another polynomial
\(P_l\) and \(P(x) = a + x \times P_l(x)\).  Here another case distinction mut be
studied, depending on whether \(a\) is zero or negative.

If \(a\) is negative, we cannot use an induction hypothesis, because in
this case \(l\) is only guaranteed to satisfy the predicate 
{\tt alternate\_1}.  On the other hand, the invariant for {\tt alternate\_1}
guarantees the existence of an \(x\) so that \(x\times P_l(x)\) is positive
and smaller than \(-a\), this \(x\) is the right witness and the slope is
\(P_l(x)\).  Since \(P_l\) is negative at the left of \(x\) it is easy to
prove that \(y\times P_l(y)\) is negative when \(0 < y \leq x\), and thus
\(P(y)\) is negative.  To reason on the slope, we use our lemma about the
slope of \(x \times P(x)\), using \(0\) for the slope of \(P\) (we only
know that it is increasing).

If {\tt a} is
zero, we have by induction hypothesis that there exists an \(x\) and \(k\)
so that \(P_l\) is negative on the left of \(x\) and has a slope larger than
\(k\) on the right of \(x\).  However, this does not guarantee that \(x\) is
the right witness for \(P\) because the slope of \(x\times P_l(x)\) is only
larger than \(P_l(x) + x \times k\), and \(P_l(x)\) is negative.  The solution
is to note that \(P_l\) necessary takes a positive value in some point \(v1\)
on the right of \(x\) and to use our
{\em constructive intermediate value theorem} to
build a new value \(x_1\) so that \(-\frac{k v_1}{2} \leq P_l(x_1) \leq 0\).
Now \(P_l\) is still guaranteed to be negative between \(x\) and \(x_1\),
because of the slope condition and now the slope on the right of \(x_1\) is
guaranteed to be larger than \(\frac{v1 k}{2}\), which is positive.

\section{From Bernstein to Descartes}
\label{sec:Bernstein}
In this section, we first give an intuitive understanding of the Bernstein
coefficients, especially to show why they are so useful at deciding whether
a polynomial has a root in a given interval.  Then,
we clarify the polynomial transformations that link
the problem of finding the roots of a polynomial inside an arbitrary
bounded interval \((l,r)\) successively with the problem of finding
the roots of an other polynomial inside the interval \((0,1)\) and
with the problem of finding the roots of yet another polynomial inside
the interval \((0,+\infty)\).

\subsection{A geometric understanding of Bernstein coefficients}
The Bernstein coefficients are related to a broken line (made of
contiguous straightline segments) which gives a rough approximation of the
polynomial's function graph.  More precisely, given the bounds \((l,r)\)
of the interval,
the bernstein coefficients \((b_0,\ldots, b_n)\) define a collection of points
with coordinates \(c_i = (l + i \frac{r-l}{n}, b_i)\) each of these points describes
the behavior of the polynomial when the input \(x\) is close to
\(l+i\frac{r-l}{n}\).  In a sense, Bernstein coefficients can be said to
{\em control} the behavior of the polynomial in some part of the interval.
This is why the points \(c_i\) are often called {\em control points}.
These points can
be move about the vertical line \(x=l + i\frac{r-l}{n}\).  When \(b_i\) is
close to the average between \(b_{i-1}\) and \(b_{i+1}\) (in other words, when
\(c_i\) is close to the segment joining \(c_{i-1}\) and \(c_{i+1}\)), the
behavior of the polynomial in this area is quite eventless.  But when \(c_i\)
is significantly removed from this segment, \(c_i\) appears to be pulling the
polynomial's curve in its direction, with the curve of the polynomial usually
crossing the vertical line \(x=l+i\frac{r-l}{n}\) between the segment and
the point \(c_i\).  This is illustrated in the Figure~\ref{control}.
\begin{figure}
\begin{center}
\begin{tabular}{ccc}
\includegraphics[width=.30\textwidth,clip=true, trim=2cm 4cm 1cm 6.3cm]
{control.pdf}&
\includegraphics[width=.30\textwidth,clip=true, trim=2cm 4cm 1cm 6.3cm]
{control2.pdf}&
\includegraphics[width=.30\textwidth,clip=true, trim=2cm 4cm 1cm 6.3cm]
{control3.pdf}\\
(a) 1, 3, -10, 1, 4, 1 & (b) 1, 3, -1, 1, 4, 1 & (c) 3, 0, 1, 10, -2, -1\
\end{tabular}
\end{center}
\caption{\label{control} Bernstein Control points and corresponding polynomial curves}
\end{figure}

In Figure~{(\ref{control}-a)} the illustration shows that a peak in
the disposition of the control points corresponds to a bend in the
polynomial's curve (the Bernstein coefficients are 1, 3, -10, 1, 4, 1
and -10 corresponds to a downward peak).  In this case, the peak
provokes two sign changes, which are reproduced in the shape of the
curve and correspond to the existence of two roots inside the
interval.  In Figure~(\ref{control}-b), the coefficients still exhibit
a downward peak with a negative coefficient, but the polynomial's
curve stays away from the x-axis and the two sign changes in the
Bernstein coefficients do not correspond to any real root for the
polynomial (this is a false alert).  In Figure~(\ref{control}-c),
there is on sign change, so that the first and last coefficients have
opposite signs.  In fact, the first and the last Bernstein
coefficients are equal to the values of the polynomial at the bounds
of the interval, so this imposes the existence of at least one root.
But because there is exactly one sign change in the coefficients, we
can be sure that any other bend in the curve stays away of the x-axis.

Proving the properties of Bernstein coefficients works by establishing
a route from Descartes' law of signs to Bernstein coefficients.  Descartes'
law of sign works for the interval \(0,+\infty\).  This criterion
can easily be adapted to any half-line interval \((a,+\infty)\) and
more precisely to \((1,+\infty)\).  Then a criterion on \((1,+\infty)\)
can be transformed into a criterion on \((0,1)\). This can, in turn,
be transposed to any interval.  It happens that this path gives a way to
reason on Bernstein coefficients.
\subsection{A criterion for the interval \((1,+\infty)\)}
The law of signs gives us a sufficient condition to determine when the
unbounded interval \((0,+\infty)\) contains exactly one root for a
polynomial. Through a change of variable, we obtain a similar
criterion for the interval \((1, +\infty)\).

 The polynomial \(P(x)\)
has exactly one root in the interval \((1,+\infty)\) if and only if
the polynomial function \(y \mapsto P(y+1)\) has exactly one root in
the interval \((0,+\infty)\). Expressed in termes of the
coefficients \(a_i\) of the polynomial
\(P\), we have \[P(y+1)= \sum_{i=0}^{n} a_i (y+1)^i = \sum_{k=0}^{n}
\sum_{i=k}^{n}a_i\left(\begin{array}{c}i\\k\end{array}\right) y^k\]

Thus, if we apply Descartes's law of sign on the coefficients
\(\sum_{i=k}^{n}a_i\left(\begin{array}{c}i\\k\end{array}\right)\), we
can obtain a sufficient criterion for the existence of exactly one
root of polynomial \(P=\sum_{i=0}^{n}a_ix^i\) in the interval
\((1,+\infty)\).

With our approach to describe unique roots of polynomials inside
unbounded intervals, we can easily establish a correspondence between
the way we express existence of a unique root for the two intervals.
\subsection{A criterion for the interval \((0,1)\)}
Descartes' law of signs works for unbounded intervals.  In this
section, we see how to cover also bounded intervals. The trick now relies
on reversing the polynomial's list of coefficients.  Obviously, the
number of sign changes in a list of coefficients is the same as the
number of sign changes in the reversed list.

However, the roots of a polynomial on the interval \((1,+\infty)\)
infinity are in one-to-one correspondence with the roots of the
reversed polynomial between zero and one. This is due to the following
equation:
\[\sum_{i=0}^{n}a_i x^i = x^n\times\sum_{i=0}^{n}a_i x^{i-n}\]
We can now perform another change of variable, here \(y=1/x\) and a
change of index \(j=n-i\) in the sum.
\[\sum_{i=0}^{n}a_i x^l = (\frac{1}{y})^n \sum_{j=0}^{n}a_{n-j} y^j\]
The polynomial \(\sum_{j=0}^{n} a_{n-j}y^j\) is exactly the reversed
polynomial, and the expression \((\frac{1}{y})^n\) never becomes 0 for
\(y\in (0,1)\).  Thus, \(x\) is a root of the polynomial between \(1\)
and \(+\infty\) if and only if \(y=x^-1\) is a root of the reversed
polynomial between \(0\) and \(1\).

For instance, we can consider the polynomial \(P(x) = x^3 - 5/2 x^2 - 2 x + 3/2\),
the reversed polynomial is \(Q(x) = 3/2 x^3 - 2 x^2 - 5/2 x + 1\) and after
the variable change we obtain the polynomial \(3/2 x^3 + 5/2 x^2 - 2 x - 2\)
which exhibits only one sign change.  This predicts that the polynomial has
exactly one root between 0 and 1, and indeed the three roots of the initial
polynomial are -1, 1/2, and 3.  This is illustrated in
figure~\ref{invert} where the curve with a solid line is the curve for the
polynomial \(P\), while the curve with a dashed line is the curve for
the polynomial \(Q\), which has a single root between 1 and \(+\infty\).
\begin{figure}\label{invert}
\begin{center}
\includegraphics[clip=true,trim=3cm 5cm 3cm 14cm, width=0.5\textwidth]{invert.pdf}
\end{center}
\caption{Curves of \(x^3 -\frac{5}{2} x^2 - 2 x +
  \frac{3}{2}\)
and its reverse \(\frac{3}{2}x^3 -2 x^2 - \frac{5}{2} x + 1\)}
\end{figure}

With our approach to describe unique roots of polynomials, we need to
establish a correspondence between the criterion for unbounded
intervals and the criterion for bounded intervals. As this proof also
involves composition with the inverse function, this is one of the
trickiest proofs in our developments, in particular when we need to
find the sub-interval and the slope that is guaranteed on this
interval.  This is a place where our constructive intermediate value
theorem plays a role.

\subsection{handling arbitrary bounded intervals}

The next step is to relate the roots of any polynomial inside an
arbitrary interval\footnote{We name the bound \(l\) for {\em left} and
  \(r\) for {\em right}.} \((l,r)\) with the roots of another
polynomial inside the interval \((0,1)\).  This is done with another
change of variable, this time \(x= (r-l) y + l\); in other words, the
polynomial function which maps any \(x\) to \(p(x)\) has a root
between \(l\) and \(r\) if and only if the polynomial function which
maps any \(y\) to \(p((r - l) y + l)\) has a root between 0 and 1.

This is illustrated in figure~\ref{expand-translate}, where the shape
of the curve for the polynomial \(\frac{x^3}{8} - \frac{x^2}{8} + 3
x\) inside the interval \((2,4)\) is reproduced by the shape of the
curve for the polynomial \(x^3 -\frac{5}{2}x^2-2x+\frac{3}{2}\) inside
the theorem \((0,1)\).
\begin{figure}
\begin{center}\label{expand-translate}
\includegraphics[clip=true,trim=4.5cm 18cm 2cm 3cm, width=0.5\textwidth]{expand-translate.pdf}
\end{center}
\caption{Curves of a polynomial inside \((2,4)\) and the
  corresponding transformed polynomial between \((0,1)\)}
\end{figure}
\subsection{Recapitulating operations}\label{ssec:ops}
In our formal development, we defined three operations for
translating, expanding, and reversing the list of coefficients.  The
Bernstein coefficients for a polynomial \(p\) and an interval \((l,r)\)
are then obtained by, first expanding (composing \(p\) with 
\(x\mapsto (r-l) x + l\), then reversing the list of coefficients, and
then translating, i.e. composing with \(x \rightarrow x - 1\).  The
coefficients we obtain through this process, \(c_i\) are related to the
Bernstein coefficients \(b_i\)
in the sense that \(c_i = \left(\begin{array}{c}i\\n
\end{array}\right)b_i\), thus their sign is exactly the sign of the
Bernstein coefficients.  It is thus enough to reason on the signs of
the coefficients \(c_i\).  We show that one sign changes in these coefficients
is sufficient to ensure the existence of exactly one root in the interval
\((l,r)\).  In particular:

\begin{itemize}
\item translating a polynomial preserves the criterion for existence
of exactly one root in bounded intervals and in unbounded intervals,
\item expanding a polynomial preserves the criterion for existence of
  exactly one root in bounded intervals,
\item reversing the list of coefficients maps a polynomial satisfying
  the criterion for the existence of exactly one root in the unbounded
  interval \((1,+\infty)\) into a polynomial satisfying the criterion
  for the existence of exactly one root in the bounded interval \((0,1)\).
\end{itemize}

\section{Dichotomy}
\label{dichotomy}
Bernstein coefficients give precise information when they exhibit
either zero or one sign change. in the first case, we have the
guarantee that there are no roots of the considered polynomial in the
considered interval. In the second case, we have the guarantee that
there is exactly one root.

When Bernstein coefficients exhibit more than one sign change, no
conclusion can be drawn about the existence and unicity of roots in the
interval.  For instance, in Figure~(\ref{control}.b), the Bernstein
coefficients exhibit two sign changes, but there is no root inside the
interval.  When facing this kind of unconclusive information, the solution
is to refine the approximation given by the control line.

\subsection{Geometric intuition for dichotomy}
\label{ssec:dichogeom}
When cutting an interval in two halves, the number of control points is
approximately doubled, because each of the new half-intervals receives a
new sequence of \(n\) bernstein coefficients.  As a result, the control points
are closer to each other and to the polynomial's curve and they give a more
accurate account of the curve's position with respect to the x-axis.  This is
illustrated in Figure~\ref{dichotomy-curve}, where the initial Bernstein
coefficients exhibit a sign change, which is needed to account for the bend
in the first half of the interval (a positive local minimal, but expressed
by a negative Bernstein coefficient).  In the halved interval two more points
are added in the vicinity of the bend, and none of the control points needs
to be negative anymore.
\begin{figure}
\begin{center}
\includegraphics[clip=true,trim=2cm 12cm 1cm 11cm,width=0.6\textwidth]{control4.pdf}
\caption{\label{dichotomy-curve}Bernstein control points for halved intervals}
\end{center}
\end{figure}

In Figure~\ref{dichotomy-curve}, the dotted line represents
the polynomial's curve, the solid line links the control points for
the largest interval, marked by round bullets (the Bernstein coefficients are
1, 3, -1, 1, 4 1 for this interval).  The dashed line links the control points
for the two half intervals, marked by square boxes
(the Bernstein coefficients are 1, 2, 1.5, 1,
0.9375, 1.15625 for the first interval, and 1.15625, 1.375, 1.875, 2.5, 2.5,
1 for the second interval).  This figure illustrates that the control line
really gets closer to the polynomial's curve, and provides a much better
approximation of the polynomial.

It may seem that computing Bernstein polynomials is a costly process, however
it happens that there is a very simple method to deduce Bernstein coefficients
for one interval from coefficients for another interval.

\subsection{splitting algorithm}\label{ssec:split}
Around 1950, De Casteljau noticed that the coefficients for the sub intervals
were easy to compute from the coefficients for the big interval
through a simple recursive process. We have also proved the
correctness of this algorithm. This proof is the topic of the next
section.

In the initialization of the algorithm described in section
\ref{ssec:dicho}, the Bersnstein coeffcients of the polynomial are
computed using the transformations studied in section \ref{ssec:ops}.
Yet the computational interest of this dichotomy process lies in the
fact that given three pairwise distinct rational numbers $a, b, m$,
there exists an efficient algorithm to deduce the two repsective lists
of Bernstein coefficients of a polynomial $P$ on intervals $(a, m)$
and $(m, b)$ from the list of Bernstein coefficients of $P$ on
interval $(a, b)$. Hence the new Bernstein coefficients needed at the
recursive call of step {\bf (3)} are easy to obtain, thanks to the
so-called de Casteljau algorithm, named after its inventor, an
ingeneer in French car industry.

Let \C{c} be the sequence of coefficients of a polynomial $q$
in the Bernstein basis of degree $p$ with parmeters $a\in \mathbb{Q}$
and $b\in \mathbb{Q}$. Let $m\in \mathbb{Q}$ be a rational number
distinct from $a$ and $b$. We pose
$\alpha := \frac{m - a}{b - a}$ and $\beta := \frac{b - m}{b -a}$. The
\C{|*de_casteljau*|} algorithm is defined recursively by:
\begin{lstlisting}
  Fixpoint |*de_casteljau*| (alpha beta : Qcb) (c : nat -> Qcb) (n : nat) :=
    match n with
    | O => b
    | i.+1 => fun j =>
      (alpha * de_casteljau c i j + beta * de_casteljau c i j.+1)
  end.
\end{lstlisting}
where the initial sequence of coefficients \C{c} is represented by an
infinite sequence of rational numbers, for which only the $p$ first
elements are relevant.
It computes the two expected new Bernstein coefficients lists:
\begin{lstlisting}
  Definition |*dicho'*| alpha beta c i :=
    de_casteljau alpha beta c i 0.
\end{lstlisting}
give the Berstein coefficients of $P$ on the finite interval with
bounds $a$ and $m$, and:
\begin{lstlisting}
  Definition |*dicho*| alpha beta p c i :=
     de_casteljau alpha beta c (p - i) i.
\end{lstlisting}
gives the Bernstein coefficients of $P$ on the finite interval with
bounds $m$ and $b$. Note that if in our case, we will only use the de
Casteljau algorithm with $m$ the midpoint of the initial interval, we
do not make here any assumption on the respective positions of $a, b$
and $m$. The aim of this section is to prove that this algorithms is
correct, i.e. that the \C{|*dicho*|} and \C{|*dicho'*|} function
indeed computes the expected Bernstein coefficients. The correctness
theorems as stated in \Coq{} are:
\begin{lstlisting}
Lemma |*dicho'_correct*| : forall (a b m : Qcb)(q : {poly Qcb})(p : nat)
(c : nat -> Qcb)
(alpha := (b - m) * (b - a)^-1) (beta := (m - a) * (b - a)^-1),
  m != a ->
  q = \sum_(i < p.+1)(c i) * bernp a b p i ->
  q = \sum_(j < p.+1)(dicho' alpha beta c j) * bernp a m p j.

Lemma |*dicho_correct*| : forall (a b m : Qcb)(q : {poly Qcb})(p : nat)
(c : nat -> Qcb)
(alpha := (b - m) * (b - a)^-1) (beta := ((m - a) * (b - a)^-1)),
  m != b ->
  q = \sum_(i < p.+1)(c i) * bernp a b p i ->
  q = \sum_(j < p.+1)(dicho alpha beta p c j) * bernp m b p j.
\end{lstlisting}
where \C{(bernp a b p i)} is the $i$-th polynomial in the Bernstein
basis of degree $p$ with paramters $a$ and $b$.
\begin{figure}[ht]\label{bern}
\begin{center}
\includegraphics[width=0.5\textwidth]{bern1.pdf}
\end{center}
\caption{Properties of de Casteljau computations}
\end{figure}


The properties of computations performed by the de Casteljau algorithm
are summarized on Figure \ref{bern}. Starting from the input list
$c := (b_0^(0)\dots b_p^{(0)})$ of coefficients in the basis with
parameters $a$ and $b$, on the upper side of the triangle, it
computes the full triangle, so that in the end the two expected output
lists can be read on the two  other sides of the triangle. The list
$c' := b_0^{(0)} \dots b_0^{(j)} \dots b_0^{(p)}$ is the list of
coefficients in the basis with parameters $a$ and $m$ output by
\C{dicho'}. The list
$c'' := b_0^{(p)} \dots b_j^{(p - j)} \dots b_p^{0}$
 is the list of coefficients in the basis with parameters $m$ and $b$
 output by \C{dicho}.  The green area on Figure \ref{bern} show which values
a the computation of an arbitrary given point in the triangle relies on.
This structure is imposed by the fixpoint
 equation of the recursive definition of the de Casteljau algorithm:
\begin{lstlisting}
  de_casteljau alpha beta c n.+1 i =
  (de_casteljau alpha beta c n i) + (de_casteljau alpha beta c n i.+1)
\end{lstlisting}
which looks very similar to the recursive relation governing the
Pascal triangle.

Let us first notice that the shape of Bernstein polynomials implies
that:
\begin{lstlisting}
Lemma |*bern_swap*| :
 forall p i l r,
 (i <= p) -> r != l ->  bernp r l p i = bernp l r p (p - i).
\end{lstlisting}
This remark implies that if $c$ is the list of coefficients of the
polynomial $q$ in the Bernstein basis of degree $p$ with parameters
$a$ and $b$, then the reverse of $c$ is the list of coefficients of
the same polynomial $q$ in the Bernstein basis of degree $p$ with
parameters $b$ and $a$: reversing the list swaps the parameters:

\begin{lstlisting}
Lemma |*bern_rev_coef*| : forall (p : nat)(a b : Qcb)(c : nat -> Qcb),
  \sum_(i < p.+1)(c i) * (bernp a b p i) =
  \sum_(i < p.+1)(c (p - i)) * (bernp b a p i).
\end{lstlisting}
This remark shows that the correctness of the \C{dicho'} function is
enough to get a certified computation of both Bernstein coefficient
lists: if $c$ is the
initial list of Bernstein coefficients with parameters $a$ and $b$, then
reversing $c$ gives the  coefficients with parameters $b$ and $a$,
applying \C{dicho'} on the reverse of $c$ using $b$, $a$ amd $m$
computes the coefficients with parameter $b$ and $m$, hence reversing
this output gives the result expected for \C{dicho} on $c$ using $a$,
$b$ and $m$. Using a similar symmetry reasoning on the
\C{de_casteljau} algorithm, we in fact reduce the proof of the
\C{dicho_correct} specification to the proof of \C{dicho'_correct}.

By linearity, we can also reduce the proof of the \C{dicho'_correct}
specification to the case where the input polynomial $q$ is in fact
itself a Bernstein polynomial. This means that the input coefficient
list $c$ only contains zeros except at one position where the
coefficient is one.

Let us first compute the expected output of the \C{dicho'} function on
a such a list. In other words, for any distinct rational numbers $a,
b, m$ and any $p\in \mathbb{N}$, given $i \leq p$, we want to compute
the coefficients of:
$$Bern_{p, i}(a, b) := \binom{p}{i} \frac{(X - a)^i(X - b)^{p -i}}
{(b  - a)^p}$$ in the basis $(Bern_{p, i}(a, m))_{i = 0, \dots, p}$.
We pose
$\alpha := \frac{b -  m}{b - a}$ and $\beta := \frac{m - a}{b - a}$.
In the polynomials of the new basis, formal denominators are of the
form $(m - a)$. By noticing that:
$$\frac{X - a}{b - a} = \beta \frac{X - a}{m - a} \quad \textrm{and} \quad
\frac{b - X}{b - a} = \alpha\frac{X - a}{m - a} +\frac{m - X}{m - a}$$
and by using the binomial identity:
$$\binom{p}{i}\binom{p - i}{j - i}  = \binom{j}{i}\binom{p}{j}$$
we obtain that:
$$Bern_{p, i}(a, b) =
\sum_{j = i}^p\binom{j}{i}\alpha^{j-i}\beta^i Bern_{p, j}(a, m) \quad (*)$$
Now to achieve the proof of the \C{dicho'_correct} lemma, it is
sufficient to prove that the values output by the \C{dicho'} function
coincide with the ones of $(*)$, which boils down to an induction on $i$.


\section{Formalization issues}
\label{sec:formal}
(assia : should this material be colllected in a final section or
should it be disseminated throughout the paper?)

\begin{itemize}
\item Polynomials (stratified rings)
\item Ordered rings
\item Big operations
\item Lack of automation: ring to be ported, what about ordered rings?
\end{itemize}

{\sf travaux reliés: Bridges et Bishop sur la continuité uniforme, qui est
également utilisée dans nos travaux.}
\bibliographystyle{alpha}
\bibliography{biblio}


\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
